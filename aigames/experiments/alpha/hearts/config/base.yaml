training_hypers:
    _target_: aigames.training_manager.hyperparameters.AlphaMultiTrainingHyperparameters
    n_parallel_games: 100
    self_play_every_n_epochs: 2
    lr: 3e-4
    discount: 1.0
    max_data_size: 3500000
    min_data_size: 1024
    dirichlet_alpha: 0.25
    dirichlet_epsilon: 0.0
    weight_decay: 1e-5
    batch_size: 1024
    data_buffer_full_size: 16_384
    save_dataset_in_checkpoint: True
    action_selector:
        _target_: aigames.mcts.mcts.GumbelActionSelector
        _args_:
            - _target_: aigames.mcts.mcts.GumbelHyperparameters
    td_lambda:
        _target_: aigames.agent.alpha_agent_multi.TDLambdaByRound
        td_lambda_schedule_list: [1, 0.9, 0.8, 0.7, 0.6, 0.5]
    training_tau:
        _target_: aigames.experiments.alpha.utils.training_taus.TrainingTauStepSchedule
        schedule: [[1.0, 200_000], [0.5, 400_000], [0.1, 600_000]]
    n_mcts_iters:
        _target_: aigames.agent.alpha_agent_multi.ConstantMCTSIters
        n_mcts_iters: 100
    network_class: aigames.experiments.alpha.hearts.network_architectures.HeartsNetwork
    network_args:
        hyperparameters:
            _target_: aigames.experiments.alpha.hearts.network_architectures.HeartsNetworkHyperparameters
ckpt_dir: ./ckpt/hearts/
debug: False
max_epochs: 1000
restore_wandb_run_id: null
restore_ckpt_path: null
gradient_clip_val: 1.0